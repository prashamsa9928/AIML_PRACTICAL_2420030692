# -*- coding: utf-8 -*-
"""WEEK - 5.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ESJy7sDQm7xjRryHDu3uw2N1hZIXDzoE
"""

# Commented out IPython magic to ensure Python compatibility.
# Step 1 - Imports and load dataset
import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler, OneHotEncoder
import matplotlib.pyplot as plt
import seaborn as sns

# %matplotlib inline

# Load CSV (change filename if needed)
df = pd.read_csv("Titanic-Dataset.csv")

# Step 2 - Overview
print("Shape:", df.shape)
print("\nFirst 5 rows:")
display(df.head())

print("\nMissing values (original):")
print(df.isnull().sum())



# Step 3 - Impute missing values
# Impute Age with median
df["Age"].fillna(df["Age"].median(), inplace=True)

# Treat empty strings as NaN then impute Embarked with mode
df["Embarked"].replace('', np.nan, inplace=True)
df["Embarked"].fillna(df["Embarked"].mode()[0], inplace=True)

print("Missing values AFTER imputation (Age & Embarked):")
print(df.isnull().sum())

# Step 4 - Standardize Fare and show before/after

print("Fare - BEFORE scaling (first 8 rows):")
print(df["Fare"].head(8))

# If Fare has NaNs, fill with median so scaler won't fail
if df["Fare"].isnull().any():
    print("Found missing Fare values - filling with median before scaling.")
    df["Fare"].fillna(df["Fare"].median(), inplace=True)

scaler = StandardScaler()
# fit_transform expects 2D array -> we keep original Fare and add Fare_scaled column
df["Fare_scaled"] = scaler.fit_transform(df[["Fare"]])[:, 0]

print("\nFare_scaled - AFTER scaling (first 8 rows):")
print(df[["Fare", "Fare_scaled"]].head(8))

#print("\nMissing values AFTER scaling (should be same as after imputation):")
#print(df.isnull().sum())

# Step 5 - Columns and Sex/Embarked before encoding
print("Columns BEFORE one-hot encoding:")
print(list(df.columns))

print("\nSex and Embarked (before encoding) - first 8 rows:")
print(df[["Sex", "Embarked"]].head(8))

# Step 6 - OneHotEncode Sex and Embarked (simple version, sklearn >= 1.2)

from sklearn.preprocessing import OneHotEncoder

# Create encoder
ohe = OneHotEncoder(drop='first', sparse_output=False)

# Fit & transform
encoded_arr = ohe.fit_transform(df[["Sex", "Embarked"]])

# Column names from encoder
encoded_cols = ohe.get_feature_names_out(["Sex", "Embarked"])

# Convert to DataFrame
encoded_df = pd.DataFrame(encoded_arr, columns=encoded_cols, index=df.index)

# Show encoded columns only
print("Encoded columns (first 8 rows):")
print(encoded_df.head(8))

import seaborn as sns
import matplotlib.pyplot as plt

# Select numerical features for plotting
num_features = ["Pclass", "Age", "SibSp", "Parch", "Fare"]

# Make sure Survived is integer
df["Survived"] = df["Survived"].astype(int)

# Pairplot grouped by Survived
sns.pairplot(df[num_features + ["Survived"]], hue="Survived", diag_kind="hist", plot_kws={"alpha":0.6})
plt.suptitle("Pairplot of Numerical Features grouped by Survived", y=1.02)
plt.show()

# Show first 5 rows of processed dataset
print("First 5 rows of the processed dataset:")
print(encoded_df.head())

# 4. Concatenate with original dataset
final_df = pd.concat([df.drop(columns=["Sex", "Embarked", "Fare"]), encoded_df], axis=1)

# 5. Show first 5 rows of processed dataset
print("First 5 rows of the final processed dataset:")
display(final_df.head())

